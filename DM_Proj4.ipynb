{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "import csv\n",
    "import pickle\n",
    "# create expanding window features\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from operator import is_not\n",
    "from functools import partial\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from apyori import apriori\n",
    "# from mlxtend.frequent_patterns import apriori\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(i):\n",
    "    \n",
    "    insulin_dataset = pd.DataFrame()\n",
    "    insulin_df = pd.read_csv(\"DataFolder/InsulinBolusLunchPat{}.csv\".format(i), sep = '\\t', header = None, skiprows = 1)\n",
    "    insulin_dataset = insulin_dataset.append(insulin_df, ignore_index = True)    \n",
    "    insulin_dataset = insulin_dataset[0].str.split(',', expand = True)\n",
    "    insulin_dataset = insulin_dataset.dropna(how = 'all')\n",
    "    insulin_dataset = insulin_dataset.fillna(0)\n",
    "    insulin_dataset = insulin_dataset.replace(\"NaN\", 0)\n",
    "    insulin_dataset = insulin_dataset.replace('', 0)\n",
    "    insulin_dataset = insulin_dataset.astype(float)\n",
    "    # insulin_dataset = insulin_dataset.astype(int)\n",
    "    insulin_dataset = np.array(insulin_dataset)\n",
    "\n",
    "    cgm_dataset = pd.DataFrame()\n",
    "    cgm_df = pd.read_csv(\"DataFolder/CGMSeriesLunchPat{}.csv\".format(i), sep = '\\t', header = None, skiprows = 1)\n",
    "    cgm_dataset = cgm_dataset.append(cgm_df, ignore_index = True)\n",
    "    \n",
    "    cgm_dataset = cgm_dataset[0].str.split(',', expand = True)\n",
    "    cgm_dataset = cgm_dataset.dropna(how = 'all')\n",
    "    cgm_dataset = cgm_dataset.fillna(0)\n",
    "    cgm_dataset = cgm_dataset.replace(\"NaN\", 0)\n",
    "    cgm_dataset = cgm_dataset.replace('', 0)\n",
    "    cgm_dataset = cgm_dataset.astype(float)\n",
    "    # cgm_dataset = cgm_dataset.astype(int)\n",
    "    cgm_dataset = np.array(cgm_dataset)\n",
    "    \n",
    "    return [insulin_dataset, cgm_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists(insulin_dataset, cgm_dataset):\n",
    "    insulin_list = []\n",
    "    for i in range(len(insulin_dataset)):\n",
    "        insulin_list.append(max(insulin_dataset[i]))\n",
    "    insulin_list = np.asarray(insulin_list)\n",
    "\n",
    "#     for i in range(len(insulin_list)):\n",
    "#         insulin_list[i] = round(insulin_list[i])\n",
    "\n",
    "    cgm_list = []\n",
    "    for i in range(len(cgm_dataset)):\n",
    "        cgm_list.append(max(cgm_dataset[i]))\n",
    "    cgm_list = np.asarray(cgm_list)\n",
    "\n",
    "    cgm_col6 = cgm_dataset[:,5]\n",
    "    \n",
    "    insulin_list= insulin_list.reshape((len(insulin_list),1))\n",
    "    cgm_list= cgm_list.reshape((len(insulin_list),1))\n",
    "    cgm_col6 = cgm_col6.reshape((len(insulin_list),1))\n",
    "    \n",
    "    return [insulin_list, cgm_list,cgm_col6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "def create_bins(lower_bound, width, quantity):\n",
    "    bins = []\n",
    "    for low in range(lower_bound, \n",
    "                     lower_bound + quantity*width + 1, width):\n",
    "        bins.append((low, low+width))\n",
    "    return bins\n",
    "\n",
    "from collections import Counter\n",
    "def find_bin(value, bins):\n",
    "    for i in range(0, len(bins)):\n",
    "        if bins[i][0] <= value < bins[i][1]:\n",
    "                return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_matrix(cgm_bins, cgm_col6_bins, insulin_list):\n",
    "    combined_matrix = np.append(cgm_bins, cgm_col6_bins, axis = 1)\n",
    "    combined_matrix = np.append(combined_matrix, insulin_list, axis = 1)\n",
    "    return combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Association_Rules(association_rules):\n",
    "    results = []\n",
    "    for item in association_rules:\n",
    "        pair=item[0]\n",
    "        items = [x for x in pair]\n",
    "        if len(items) != 3:\n",
    "            continue\n",
    "        value0 = items\n",
    "        value1=str(item[1])[:8]\n",
    "        value2=str(item[2][0][2])[:7]\n",
    "        value3=str(item[2][0][3])[:7]\n",
    "        value4 = item[2]\n",
    "        rows = (value0,value1,value2,value3,value4)\n",
    "        results.append(rows)\n",
    "        \n",
    "    labels = ['Title-1','Support','Confidence', 'Lift','Ordered Set']\n",
    "    extracted = pd.DataFrame.from_records(results,columns = labels)\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_OrderedSet(fs,os):\n",
    "    results = []\n",
    "    for item in os:\n",
    "        last = len(item)-1\n",
    "        item_1 = [x for x in item[last][0]]\n",
    "        item_2 = [y for y in item[last][1]]\n",
    "        results.append([[item_1[0], item_1[1], item_2[0]], item[last][2]])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_max_rules(os):\n",
    "    results = []\n",
    "    for item in os:\n",
    "        last = len(item)-1\n",
    "        item_1 = [x for x in item[last][0]]\n",
    "        item_2 = [y for y in item[last][1]]\n",
    "        results.append([[item_1[0], item_1[1], item_2[0]], item[last][2]])\n",
    "    max_conf_rules = []\n",
    "    \n",
    "    max_conf = 0.0\n",
    "    for i in results:\n",
    "        if max_conf < i[1]:\n",
    "            max_conf = i[1]\n",
    "    for i in results:\n",
    "        if i[1] == max_conf:\n",
    "            max_conf_rules.append(i[0])\n",
    "    return max_conf_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_min_rules(os):\n",
    "    results = []\n",
    "    for item in os:\n",
    "        last = len(item)-1\n",
    "        item_1 = [x for x in item[last][0]]\n",
    "        item_2 = [y for y in item[last][1]]\n",
    "        results.append([[item_1[0], item_1[1], item_2[0]], item[last][2]])\n",
    "    min_conf_rules = []\n",
    "    \n",
    "    min_conf = 100.0\n",
    "    for i in results:\n",
    "        if min_conf > i[1]:\n",
    "            min_conf = i[1]\n",
    "    for i in results:\n",
    "        if i[1] == min_conf:\n",
    "            min_conf_rules.append(i[0])\n",
    "    return min_conf_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "[]\n",
      "33\n",
      "38\n",
      "[6, 10, 16, 22]\n",
      "34\n",
      "75\n",
      "[0, 9, 15, 19, 24, 29, 33, 58, 72]\n",
      "66\n",
      "52\n",
      "[28]\n",
      "51\n",
      "18\n",
      "[3]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "result_freq_items= {}\n",
    "result_max_confidence_rules = {}\n",
    "result_anomalous_rules = {}\n",
    "\n",
    "for i in range(1,6):\n",
    "    [insulin_dataset, cgm_dataset]= load_csv(i)\n",
    "    [insulin_list, cgm_list,cgm_col6] = create_lists(insulin_dataset, cgm_dataset)\n",
    "\n",
    "    bins = create_bins(lower_bound=40, width=10, quantity=36)\n",
    "\n",
    "    cgm_bins = []\n",
    "    for value in cgm_list:\n",
    "        bin_index = find_bin(value, bins)\n",
    "        cgm_bins.append(bin_index+1000)\n",
    "    cgm_bins = np.array(cgm_bins)\n",
    "    cgm_bins = cgm_bins.reshape((len(cgm_list),1))\n",
    "\n",
    "    cgm_col6_bins = []\n",
    "    for value in cgm_col6:\n",
    "        bin_index = find_bin(value, bins)\n",
    "        cgm_col6_bins.append(bin_index+100)\n",
    "    cgm_col6_bins = np.array(cgm_col6_bins)\n",
    "    cgm_col6_bins = cgm_col6_bins.reshape((len(insulin_list),1))\n",
    "\n",
    "    combined_matrix = combine_matrix(cgm_bins, cgm_col6_bins, insulin_list)\n",
    "    combined_matrix = list(combined_matrix)\n",
    "    print(len(combined_matrix))\n",
    "    temp = []\n",
    "    _combined = []\n",
    "    for i in range(len(combined_matrix)):\n",
    "        if 999 in combined_matrix[i] or 99 in combined_matrix[i]:\n",
    "            temp.append(i)\n",
    "            continue\n",
    "        else:\n",
    "            _combined.append(combined_matrix[i])\n",
    "\n",
    "    combined_matrix = []\n",
    "    combined_matrix = _combined\n",
    "    print(temp)\n",
    "    print(len(combined_matrix))\n",
    "    association_rules = apriori(combined_matrix, min_support =0.001)\n",
    "    association_result = list(association_rules)\n",
    "    extracted_df = extract_Association_Rules(association_result)\n",
    "#     extracted_OS = extract_OrderedSet(extracted_df['Title-1'],extracted_df['Ordered Set'])\n",
    "    \n",
    "    for j in extracted_df['Title-1']:\n",
    "        j.sort(reverse = True)\n",
    "        j[0] -= 1000\n",
    "        j[1] -= 100\n",
    "    \n",
    "    result_freq_items[i] = extracted_df['Title-1']\n",
    "    \n",
    "#     print(\"Patient\" + str(i))\n",
    "#     print(extracted_OS)\n",
    "    \n",
    "    max_conf_rules = []\n",
    "    max_conf_rules = extract_max_rules(extracted_df['Ordered Set'])\n",
    "    for j in max_conf_rules:\n",
    "        j.sort(reverse = True)\n",
    "        j[0] -= 1000\n",
    "        j[1] -= 100\n",
    "        \n",
    "    result_max_confidence_rules[i] = max_conf_rules\n",
    "    \n",
    "    min_conf_rules=[]\n",
    "    min_conf_rules = extract_min_rules(extracted_df['Ordered Set'])\n",
    "    for j in min_conf_rules:\n",
    "        j.sort(reverse = True)\n",
    "        j[0] -= 1000\n",
    "        j[1] -= 100\n",
    "    result_anomalous_rules[i] = min_conf_rules\n",
    "\n",
    "#     print(\"Patient\" + str(i))\n",
    "#     print(max_conf_rules)\n",
    "#     print(\"haha\")\n",
    "#     print(min_conf_rules)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from csv import writer\n",
    "# def append_list_as_row(file_name, list_of_elem):\n",
    "# # Open file in append mode\n",
    "#     with open(file_name, 'a+', newline='') as write_obj:\n",
    "#     # Create a writer object from csv module\n",
    "#         csv_writer = writer(write_obj)\n",
    "#         # Add contents of list as last row in the csv file\n",
    "#         csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,6):\n",
    "# #     append_list_as_row(\"Frequent_items.csv\",[\"\\n\"])\n",
    "# #     append_list_as_row(\"Frequent_items.csv\",[\"Patient:\"+ str(i)])\n",
    "#     for j in result_freq_items[i]:\n",
    "#         append_list_as_row(\"Frequent_items.csv\",j)\n",
    "# #     append_list_as_row(\"Largest_confidence_rules.csv\",[\"\\n\"])\n",
    "# #     append_list_as_row(\"Largest_confidence_rules.csv\",[\"Patient:\"+str(i)])\n",
    "#     for j in result_max_confidence_rules[i]:\n",
    "#         append_list_as_row(\"Largest_confidence_rules.csv\",j)\n",
    "# #     append_list_as_row(\"Anomalous_rules.csv\",[\"\\n\"])\n",
    "# #     append_list_as_row(\"Anomalous_rules.csv\",[\"Patient:\"+str(i)])\n",
    "#     for j in result_anomalous_rules[i]:\n",
    "#         append_list_as_row(\"Anomalous_rules.csv\",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
