{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "import csv\n",
    "import pickle\n",
    "# create expanding window features\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from operator import is_not\n",
    "from functools import partial\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(i):\n",
    "    \n",
    "    insulin_dataset = pd.DataFrame()\n",
    "    insulin_df = pd.read_csv(\"DataFolder/InsulinBolusLunchPat{}.csv\".format(i), sep = '\\t', header = None, skiprows = 1)\n",
    "    insulin_dataset = insulin_dataset.append(insulin_df, ignore_index = True)    \n",
    "    insulin_dataset = insulin_dataset[0].str.split(',', expand = True)\n",
    "    insulin_dataset = insulin_dataset.dropna(how = 'all')\n",
    "    insulin_dataset = insulin_dataset.fillna(0)\n",
    "    insulin_dataset = insulin_dataset.replace(\"NaN\", 0)\n",
    "    insulin_dataset = insulin_dataset.replace('', 0)\n",
    "    insulin_dataset = insulin_dataset.astype(float)\n",
    "    # insulin_dataset = insulin_dataset.astype(int)\n",
    "    insulin_dataset = np.array(insulin_dataset)\n",
    "\n",
    "    cgm_dataset = pd.DataFrame()\n",
    "    cgm_df = pd.read_csv(\"DataFolder/CGMSeriesLunchPat{}.csv\".format(i), sep = '\\t', header = None, skiprows = 1)\n",
    "    cgm_dataset = cgm_dataset.append(cgm_df, ignore_index = True)\n",
    "    \n",
    "    cgm_dataset = cgm_dataset[0].str.split(',', expand = True)\n",
    "    cgm_dataset = cgm_dataset.dropna(how = 'all')\n",
    "    cgm_dataset = cgm_dataset.fillna(0)\n",
    "    cgm_dataset = cgm_dataset.replace(\"NaN\", 0)\n",
    "    cgm_dataset = cgm_dataset.replace('', 0)\n",
    "    cgm_dataset = cgm_dataset.astype(float)\n",
    "    # cgm_dataset = cgm_dataset.astype(int)\n",
    "    cgm_dataset = np.array(cgm_dataset)\n",
    "    \n",
    "    return [insulin_dataset, cgm_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists(insulin_dataset, cgm_dataset):\n",
    "    insulin_list = []\n",
    "    for i in range(len(insulin_dataset)):\n",
    "        insulin_list.append(max(insulin_dataset[i]))\n",
    "    insulin_list = np.asarray(insulin_list)\n",
    "\n",
    "    for i in range(len(insulin_list)):\n",
    "        insulin_list[i] = round(insulin_list[i])\n",
    "\n",
    "    cgm_list = []\n",
    "    for i in range(len(cgm_dataset)):\n",
    "        cgm_list.append(max(cgm_dataset[i]))\n",
    "    cgm_list = np.asarray(cgm_list)\n",
    "\n",
    "    cgm_col6 = cgm_dataset[:,6]\n",
    "    \n",
    "    insulin_list= insulin_list.reshape((len(insulin_list),1))\n",
    "    cgm_list= cgm_list.reshape((len(insulin_list),1))\n",
    "    cgm_col6 = cgm_col6.reshape((len(insulin_list),1))\n",
    "    \n",
    "    return [insulin_list, cgm_list,cgm_col6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "def create_bins(lower_bound, width, quantity):\n",
    "    bins = []\n",
    "    for low in range(lower_bound, \n",
    "                     lower_bound + quantity*width + 1, width):\n",
    "        bins.append((low, low+width))\n",
    "    return bins\n",
    "\n",
    "from collections import Counter\n",
    "def find_bin(value, bins):\n",
    "    for i in range(0, len(bins)):\n",
    "        if bins[i][0] <= value < bins[i][1]:\n",
    "                return i\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_matrix(cgm_bins, cgm_col6_bins, insulin_list):\n",
    "    combined_matrix = np.append(cgm_bins, cgm_col6_bins, axis = 1)\n",
    "    combined_matrix = np.append(combined_matrix, insulin_list, axis = 1)\n",
    "    return combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(combined_matrix):\n",
    "    _dict = {}\n",
    "    for i in combined_matrix:\n",
    "        temp = str(i[0])+','+str(i[1])+','+str(i[2])\n",
    "        if temp in _dict:\n",
    "            _dict[temp] += 1\n",
    "        else:\n",
    "            _dict[temp] = 1\n",
    "\n",
    "    _set = set(_dict.values())\n",
    "    return(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequent_items(_dict):\n",
    "    freq_items = []\n",
    "    maximum_frequent = max(_dict.values())\n",
    "    for i in _dict:\n",
    "        if _dict[i] == maximum_frequent:\n",
    "            freq_items.append(i)\n",
    "    return [freq_items,maximum_frequent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_largest_confidence(combined_matrix, freq_items,maximum_frequent):\n",
    "    confidence = {}\n",
    "    for i in freq_items:\n",
    "        count=0\n",
    "        temp_list = []\n",
    "        _list = i.split(',')\n",
    "        _list[0] = float(_list[0])\n",
    "        _list[1] = float(_list[1])\n",
    "        for j in combined_matrix:\n",
    "            if j[0] == _list[0] and j[1] == _list[1]:\n",
    "                count+=1\n",
    "                temp_list.append(j)\n",
    "        confidence[i] = round(maximum_frequent/count, 2)\n",
    "    #     print(temp_list)\n",
    "    \n",
    "    for i in confidence:\n",
    "        if confidence[i] != max(confidence.values()):\n",
    "            confidence.pop(i)\n",
    "    return(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_confidence(combined_matrix,_dict):\n",
    "    confidence = {}\n",
    "    for i in _dict:\n",
    "        count = 0\n",
    "        temp_list = []\n",
    "        _list = i.split(',')\n",
    "        _list[0] = float(_list[0])\n",
    "        _list[1] = float(_list[1])\n",
    "        for j in combined_matrix:\n",
    "            if j[0] == _list[0] and j[1] == _list[1]:\n",
    "                count+=1\n",
    "                temp_list.append(j)\n",
    "        confidence[i] = round(_dict[i]/count, 2)\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confidences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c87ba80c0d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0m_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mfreq_items\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaximum_frequent\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_frequent_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mlargest_confidences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_largest_confidence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximum_frequent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#     largest_confidence_rules = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-cf94882ab05b>\u001b[0m in \u001b[0;36mcalculate_largest_confidence\u001b[1;34m(combined_matrix, freq_items, maximum_frequent)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#     print(temp_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mconfidences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confidences' is not defined"
     ]
    }
   ],
   "source": [
    "result_freq_items= {}\n",
    "result_max_confidence_rules = {}\n",
    "result_anomalous_rules = {}\n",
    "\n",
    "for i in range(1,6):\n",
    "    [insulin_dataset, cgm_dataset]= load_csv(i)\n",
    "    [insulin_list, cgm_list,cgm_col6] = create_lists(insulin_dataset, cgm_dataset)\n",
    "\n",
    "    bins = create_bins(lower_bound=0, width=10, quantity=400)\n",
    "\n",
    "    cgm_bins = []\n",
    "    for value in cgm_list:\n",
    "        bin_index = find_bin(value, bins)\n",
    "        cgm_bins.append(bin_index)\n",
    "    cgm_bins = np.array(cgm_bins)\n",
    "    cgm_bins = cgm_bins.reshape((len(cgm_list),1))\n",
    "\n",
    "    cgm_col6_bins = []\n",
    "    for value in cgm_col6:\n",
    "        bin_index = find_bin(value, bins)\n",
    "        cgm_col6_bins.append(bin_index)\n",
    "    cgm_col6_bins = np.array(cgm_col6_bins)\n",
    "    cgm_col6_bins = cgm_col6_bins.reshape((len(insulin_list),1))\n",
    "\n",
    "    combined_matrix = combine_matrix(cgm_bins, cgm_col6_bins, insulin_list)\n",
    "    _dict = create_dict(combined_matrix)\n",
    "    [freq_items,maximum_frequent] = find_frequent_items(_dict)\n",
    "    largest_confidences = calculate_largest_confidence(combined_matrix, freq_items, maximum_frequent)\n",
    "  \n",
    "#     largest_confidence_rules = []\n",
    "#     max_conf = max(largest_confidences.values())\n",
    "#     for t in largest_confidences:\n",
    "#         if largest_confidences[t] == max_conf:\n",
    "#             largest_confidence_rules.append(t)\n",
    "    \n",
    "    anom_confidence = calculate_all_confidence(combined_matrix,_dict)\n",
    "\n",
    "    anom_rules = []\n",
    "    for j in anom_confidence:\n",
    "        if anom_confidence[j] == min(anom_confidence.values()):\n",
    "            anom_rules.append(j)\n",
    "            \n",
    "    result_freq_items[i] = freq_items\n",
    "    result_max_confidence_rules[i] = largest_confidences\n",
    "    result_anomalous_rules[i] = anom_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_max_confidence_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "# Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "    # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    append_list_as_row(\"Frequent_items.csv\",[\"\\n\"])\n",
    "    append_list_as_row(\"Frequent_items.csv\",[\"Patient:\"+ str(i)])\n",
    "    for j in result_freq_items[i]:\n",
    "        append_list_as_row(\"Frequent_items.csv\",[j])\n",
    "    append_list_as_row(\"Largest_confidence_rules.csv\",[\"\\n\"])\n",
    "    append_list_as_row(\"Largest_confidence_rules.csv\",[\"Patient:\"+str(i)])\n",
    "    for j in result_max_confidence_rules[i]:\n",
    "        append_list_as_row(\"Largest_confidence_rules.csv\",[j])\n",
    "    append_list_as_row(\"Anomalous_rules.csv\",[\"\\n\"])\n",
    "    append_list_as_row(\"Anomalous_rules.csv\",[\"Patient:\"+str(i)])\n",
    "    for j in result_anomalous_rules[i]:\n",
    "        append_list_as_row(\"Anomalous_rules.csv\",[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
